{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9851b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import higra as hg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from toolz import curry\n",
    "\n",
    "from cucim.skimage.transform import downscale_local_mean\n",
    "from cucim.skimage.filters import median\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tifffile import imread\n",
    "\n",
    "from dexp.processing.morphology import area_white_top_hat\n",
    "\n",
    "from dexp_dl.inference import ModelInference\n",
    "from dexp_dl.postprocessing import hierarchy\n",
    "from dexp_dl.models import hrnet, unet\n",
    "from dexp_dl.transforms import *\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "SPARSE_DECONV_PATH = f'{os.environ[\"HOME\"]}/Softwares/sparse-decon-py'\n",
    "sys.path.append(SPARSE_DECONV_PATH)\n",
    "\n",
    "try:\n",
    "    from sparse_recon.sparse_deconv import sparse_deconv\n",
    "except ImportError:\n",
    "    sparse_deconv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a488411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT ###\n",
    "IM_PATH = '10somite 100821 sample2 20x_1_MMStack_Default.ome.tif'\n",
    "WEIGHTS_PATH = 'logs/hrnet_bn/last.ckpt'\n",
    "CELL_CHANNEL = 2\n",
    "Z_SCALE = 2\n",
    "DATASET_PATH = IM_PATH.split('.')[0] + '.csv'\n",
    "\n",
    "th.cuda.set_device(0)\n",
    "\n",
    "### PARAMETERS ###\n",
    "PRED_THOLD = 0.25\n",
    "CUT_THOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de184c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing keys []\n",
      "\n",
      "Unexpected keys []\n"
     ]
    }
   ],
   "source": [
    "def in_transform(image):\n",
    "    return th.Tensor(image).unsqueeze_(0).half()\n",
    "\n",
    "def out_transform(image):\n",
    "    return th.sigmoid(F.interpolate(image, scale_factor=2, mode='trilinear', align_corners=True))\n",
    "\n",
    "def normalize(image, upper_limit):\n",
    "    im_min = image.min()\n",
    "    image = (image - im_min) / (quantile - im_min)\n",
    "    return np.clip(image, 0, 1)\n",
    "\n",
    "net = hrnet.hrnet_w18_small_v2(pretrained=False, in_chans=1, num_classes=3, image_ndim=3)\n",
    "\n",
    "model = ModelInference(\n",
    "    net,\n",
    "    transforms=in_transform,\n",
    "    after_transforms=out_transform,\n",
    "    tile=(48, 96, 96), num_outputs=3,\n",
    ")\n",
    "\n",
    "model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a18e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(IM_PATH)\n",
    "if image.shape[1] < 5:\n",
    "    image = image.transpose((1, 0, 2, 3))\n",
    "    \n",
    "# making it anisotropic\n",
    "image = downscale_local_mean(cp.asarray(image), (1, Z_SCALE, 1, 1)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39caad20-0593-4d76-95d6-803f469d483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wth = np.stack([\n",
    "    area_white_top_hat(image[i], 1e4, sampling=1, axis=0) for i in range(len(image))\n",
    "])\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image, name='before', channel_axis=0)\n",
    "viewer.add_image(wth, name='after', channel_axis=0)\n",
    "\n",
    "# wth0 = np.stack([\n",
    "#     white_top_hat(image[i], 0) for i in range(len(image)\n",
    "# ])\n",
    "# viewer.add_image(wth0, name='after 0', channel_axis=0)\n",
    "# viewer.add_image(wth.astype(np.int16) - wth0, name='dif', channel_axis=0)\n",
    "\n",
    "image = wth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb980c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = np.quantile(image[CELL_CHANNEL], 0.999)\n",
    "print('Quantile', quantile, 'Maximum', image[CELL_CHANNEL].max())\n",
    "\n",
    "# normalizing image\n",
    "norm_image = normalize(image[CELL_CHANNEL], quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734bc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "with th.cuda.amp.autocast():\n",
    "    pred = model(norm_image)\n",
    "    \n",
    "th.cuda.empty_cache()  \n",
    "\n",
    "# displaying\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image, channel_axis=0, name='Input image')\n",
    "viewer.add_image(pred[0], blending='additive', name='Cell prediction')\n",
    "viewer.add_image(pred[1], blending='additive', name='Distance map')\n",
    "if len(pred) > 2:\n",
    "    viewer.add_image(pred[2], blending='additive', name='Denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing segmentation\n",
    "hiers = hierarchy.create_hierarchies(\n",
    "    pred[0] > PRED_THOLD,\n",
    "    pred[1],\n",
    "    hierarchy_fun=hg.watershed_hierarchy_by_area,\n",
    "    cache=True,\n",
    "    min_area=10,\n",
    "    min_frontier=0,\n",
    ")\n",
    "    \n",
    "for h in hiers:\n",
    "    h.cut_threshold = CUT_THOLD\n",
    "labels = hierarchy.to_labels(hiers, pred[0].shape)\n",
    "    \n",
    "labels_layer = viewer.add_labels(labels)\n",
    "labels_layer.contour = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurring expressions\n",
    "indices = list(range(len(image)))\n",
    "indices.remove(CELL_CHANNEL)\n",
    "\n",
    "expressions = image[indices].transpose((1, 2, 3, 0))\n",
    "\n",
    "n_exp = len(indices)\n",
    "viewer.add_image(expressions, name='original expressions', channel_axis=3)\n",
    "\n",
    "### DECONVOLUTION ###\n",
    "\n",
    "# change this to use/not use deconvolution\n",
    "use_deconv = False\n",
    "\n",
    "if use_deconv and sparse_deconv is None:\n",
    "    print('sparse-deconv-py package not loaded!')\n",
    "    use_deconv = False\n",
    "\n",
    "if use_deconv:\n",
    "    \"\"\"\n",
    "    Parameter description:\n",
    "    \n",
    "    background:\n",
    "        0 = no background noise\n",
    "        1 = low background noise\n",
    "        2 = high background noise\n",
    "    \n",
    "    fidelity:\n",
    "        higher values forces result to be closer to input\n",
    "    \n",
    "    sparsity:\n",
    "        higher values forces results to have more zeros --- it removes more blur/noise\n",
    "    \n",
    "    NOTE:\n",
    "        very HIGH `sparsity` and/or LOW `fidelity` might lead to an empty image as result\n",
    "    \"\"\"\n",
    "    deconv = np.zeros_like(expressions, dtype=float)\n",
    "    for i in range(expressions.shape[-1]):\n",
    "        deconv[..., i] = sparse_deconv(expressions[..., i], [], background=1, fidelity=150, sparsity=10).get()\n",
    "    \n",
    "    viewer.add_image(deconv, name='deconvolved expressions', channel_axis=3)\n",
    "    \n",
    "    expressions = deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81298f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting expressions from segments\n",
    "props = regionprops(labels, expressions)\n",
    "exp_statistics = curry(np.mean, axis=0)\n",
    "\n",
    "# spreading expression to segments\n",
    "mask = np.zeros_like(expressions)\n",
    "for p in props:\n",
    "    exps = exp_statistics(p.intensity_image[p.image])\n",
    "    for i in range(len(exps)):\n",
    "        mask[p.slice + (i,)][p.image] = exps[i]\n",
    "\n",
    "layer_colors = ('green', 'red', 'blue')\n",
    "exps_layer = viewer.add_image(mask, name='orig. label exp.', channel_axis=3)\n",
    "for c, l in zip(layer_colors, exps_layer):\n",
    "    l.colormap = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79669b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for p in props:\n",
    "    exps = exp_statistics(p.intensity_image[p.image])\n",
    "    if all(exp > l.contrast_limits[0] for exp, l in zip(exps, exps_layer)):\n",
    "        df.append([p.label, *p.centroid, *exps])\n",
    "\n",
    "df = pd.DataFrame(df, columns=['label', 'z', 'y', 'x'] + [f'exp{i}' for i in range(n_exp)])\n",
    "\n",
    "\n",
    "def normalize_column(df, column, upper_quantile=1):\n",
    "    col = df[column].values.copy()\n",
    "    minimum = col.min()\n",
    "    col -= minimum\n",
    "    quantile = np.quantile(col, upper_quantile)\n",
    "    col /= quantile\n",
    "    \n",
    "    def norm_fun(x):\n",
    "        return min(1, max(0, (x - minimum) / quantile))\n",
    "    \n",
    "    return np.clip(col, 0, 1), norm_fun\n",
    "\n",
    "# computing colors\n",
    "grb = np.array([[0, 1, 0, 1],\n",
    "                [1, 0, 0, 1],\n",
    "                [0, 0, 1, 1]])\n",
    "\n",
    "df_colors = np.zeros((len(df), 4))\n",
    "norm_funs = []\n",
    "for i in range(n_exp):\n",
    "    blending, norm_fun = normalize_column(df, f'exp{i}')\n",
    "    norm_funs.append(norm_fun)\n",
    "    df_colors += blending[:, None] * grb[i][None, :]\n",
    "\n",
    "df_colors[:,3] = 1 # alpha channel\n",
    "\n",
    "plt.scatter(x=df['exp0'], y=df['exp1'], c=df_colors)\n",
    "plt.xlabel('exp. 0'); plt.ylabel('exp. 1')\n",
    "\n",
    "df.to_csv(DATASET_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66213f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spreading expression to segments\n",
    "mask = np.zeros_like(expressions)\n",
    "for p in props:\n",
    "    exps = exp_statistics(p.intensity_image[p.image])\n",
    "    if all(exp > l.contrast_limits[0] for exp, l in zip(exps, exps_layer)):\n",
    "        for i in range(len(exps)):\n",
    "            mask[p.slice + (i,)][p.image] = norm_funs[i](exps[i])\n",
    "\n",
    "layers = viewer.add_image(mask, name='selected label exp.', channel_axis=3)\n",
    "for c, l in zip(layer_colors, layers):\n",
    "    l.colormap = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a4648-8c84-4deb-95c0-093131decf38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
