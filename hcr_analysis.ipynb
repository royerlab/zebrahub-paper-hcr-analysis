{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import higra as hg\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from toolz import curry\n",
    "\n",
    "from cucim.skimage.transform import downscale_local_mean, rescale\n",
    "from cucim.skimage.filters import gaussian\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import regionprops\n",
    "from skimage import restoration\n",
    "\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tifffile import imread\n",
    "\n",
    "from dexp_dl.inference import ModelInference\n",
    "from dexp_dl.postprocessing import hierarchy\n",
    "from dexp_dl.models import hrnet, unet\n",
    "from dexp_dl.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT ###\n",
    "IM_PATH = 'bud stage - embryo3_1_crop_denoised.tif'\n",
    "WEIGHTS_PATH = 'logs/hrnet_bn/last.ckpt'\n",
    "CELL_CHANNEL = 0\n",
    "Z_SCALE = 2\n",
    "DATASET_PATH = IM_PATH.split('.')[0] + '.csv'\n",
    "\n",
    "th.cuda.set_device(0)\n",
    "\n",
    "### PARAMETERS ###\n",
    "PRED_THOLD = 0.25\n",
    "CUT_THOLD = 1\n",
    "EXP_BLUR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de184c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def in_transform(image):\n",
    "    return th.Tensor(image).unsqueeze_(0).half()\n",
    "\n",
    "def out_transform(image):\n",
    "    return th.sigmoid(F.interpolate(image, scale_factor=2, mode='trilinear', align_corners=True))\n",
    "\n",
    "def normalize(image, upper_limit):\n",
    "    im_min = image.min()\n",
    "    image = (image - im_min) / (quantile - im_min)\n",
    "    return np.clip(image, 0, 1)\n",
    "\n",
    "net = hrnet.hrnet_w18_small_v2(pretrained=False, in_chans=1, num_classes=3, image_ndim=3)\n",
    "\n",
    "model = ModelInference(\n",
    "    net,\n",
    "    transforms=in_transform,\n",
    "    after_transforms=out_transform,\n",
    "    tile=(48, 96, 96), num_outputs=3,\n",
    ")\n",
    "\n",
    "model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a18e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(IM_PATH)\n",
    "if image.shape[1] == 3:\n",
    "    image = image.transpose((1, 0, 2, 3))\n",
    "    \n",
    "# making it anisotropic\n",
    "image = downscale_local_mean(cp.asarray(image), (1, Z_SCALE, 1, 1)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e8768-cff5-48dc-ab20-4b27fbe5e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image, channel_axis=0, name='Input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb980c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = np.quantile(image[CELL_CHANNEL], 0.999)\n",
    "print('Quantile', quantile, 'Maximum', image[CELL_CHANNEL].max())\n",
    "\n",
    "# normalizing image\n",
    "norm_image = normalize(image[CELL_CHANNEL], quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734bc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "with th.cuda.amp.autocast():\n",
    "    pred = model(norm_image)\n",
    "    \n",
    "    # displaying\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image, channel_axis=0, name='Input image')\n",
    "viewer.add_image(pred[0], blending='additive', name='Cell prediction')\n",
    "viewer.add_image(pred[1], blending='additive', name='Distance map')\n",
    "if len(pred) > 2:\n",
    "    viewer.add_image(pred[2], blending='additive', name='Denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing segmentation\n",
    "hiers = hierarchy.create_hierarchies(\n",
    "    pred[0] > PRED_THOLD,\n",
    "    pred[1],\n",
    "    hierarchy_fun=hg.watershed_hierarchy_by_area,\n",
    "    cache=True,\n",
    "    min_area=10,\n",
    "    min_frontier=0,\n",
    ")\n",
    "    \n",
    "for h in hiers:\n",
    "    h.cut_threshold = CUT_THOLD\n",
    "labels = hierarchy.to_labels(hiers, pred[0].shape)\n",
    "    \n",
    "labels_layer = viewer.add_labels(labels)\n",
    "labels_layer.contour = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeef43b-330a-4a74-9775-34d2fb6889f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveBackground:\n",
    "    \"\"\"\n",
    "    The background removal is computed using the cell predictions.\n",
    "    First the cell predictions are used to compute the median decay in intensity for each z-slice.\n",
    "    This decay is saved in the variable `self.coefs`.\n",
    "    After that, we remove the background of any given image by estimating the otsu's threshold for\n",
    "    each z-slice, computing the median threshold value and applying the previously computed decay.\n",
    "    Note: we are not centralizing the threshold to z=0 because we observed that this produces betterresults.\n",
    "    \"\"\"\n",
    "    def __init__(self, cell_mask, cell_channel, max_proj_mask=False, display=True):\n",
    "        n_slices = cell_mask.shape[0]\n",
    "        if max_proj_mask:\n",
    "            cell_mask = np.max(cell_mask, axis=0)\n",
    "            cell_mask = np.tile(cell_mask, (n_slices, 1, 1))\n",
    "            \n",
    "        self.cell_mask = cell_mask\n",
    "        cells = np.ma.MaskedArray(cell_channel, self.cell_mask)\n",
    "        y = np.ma.median(cells, axis=(1, 2))\n",
    "        if display:\n",
    "            plt.plot(y)\n",
    "        x = np.arange(len(y))\n",
    "        X = np.stack([np.ones(len(x)), x], axis=1)\n",
    "        self.coefs = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "        if display:\n",
    "            plt.plot(X @ self.coefs)\n",
    "            plt.show()\n",
    "        \n",
    "    def __call__(self, stack):\n",
    "        estimated_intensity = []\n",
    "        for t in range(len(stack)):\n",
    "            estimated_intensity.append(threshold_otsu(stack[t]))\n",
    "        x = np.arange(len(stack))\n",
    "        decay = x * self.coefs[1]\n",
    "        background_noise = np.median(estimated_intensity) + decay\n",
    "        # print(background_noise)\n",
    "        return np.clip(stack - background_noise[:, None, None], 0, None)\n",
    "    \n",
    "bkg_rem = RemoveBackground(pred[0] > 0.25, image[CELL_CHANNEL], max_proj_mask=True, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurring expressions\n",
    "if CELL_CHANNEL == 0:\n",
    "    expressions = image[1:].transpose((1, 2, 3, 0))\n",
    "elif CELL_CHANNEL == 2:\n",
    "    expressions = image[:CELL_CHANNEL].transpose((1, 2, 3, 0))\n",
    "else:\n",
    "    raise RuntimeError\n",
    "\n",
    "for c in range(len(expressions)):\n",
    "    expressions[c] = bkg_rem(expressions[c])\n",
    "    \n",
    "if EXP_BLUR > 0:\n",
    "    expressions = gaussian(cp.asarray(expressions, dtype=np.float32), sigma=EXP_BLUR, multichannel=True).get()\n",
    "viewer.add_image(expressions, name='processed expressions', channel_axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79669b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting expressions from segments\n",
    "props = regionprops(labels, expressions)\n",
    "exp_statistics = curry(np.median, axis=0)\n",
    "    \n",
    "df = []\n",
    "\n",
    "for p in props:\n",
    "    exp1, exp2 = exp_statistics(p.intensity_image[p.image])\n",
    "    df.append([p.label, exp1, exp2, *p.centroid])\n",
    "\n",
    "df = pd.DataFrame(df, columns=['label', 'tbxt', 'sox2', 'z', 'y', 'x'])\n",
    "\n",
    "# computing colors\n",
    "green = np.array([[0, 1, 0, 1]])  # tbxt\n",
    "magenta = np.array([[1, 0, 1, 1]])  # sox2\n",
    "\n",
    "def normalize_column(df, column, upper_quantile=0.95):\n",
    "    col = df[column].values.copy()\n",
    "    col -= col.min()\n",
    "    col /= np.quantile(col, upper_quantile)\n",
    "    return np.clip(col, 0, 1)\n",
    "\n",
    "tbxt = normalize_column(df, 'tbxt')\n",
    "sox2 = normalize_column(df, 'sox2')\n",
    "\n",
    "colors = green * tbxt[:, None] + magenta * sox2[:, None]\n",
    "colors[:,3] = 1 # alpha channel\n",
    "\n",
    "plt.scatter(x=df['tbxt'], y=df['sox2'], c=colors)\n",
    "plt.xlabel('tbxt'); plt.ylabel('sox2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81298f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spreading expression to segments\n",
    "mask = np.zeros(labels.shape + (2,), dtype=np.uint16)\n",
    "for p in props:\n",
    "    exp1, exp2 = exp_statistics(p.intensity_image[p.image])\n",
    "    mask[p.slice + (0,)][p.image] = exp1\n",
    "    mask[p.slice + (1,)][p.image] = exp2\n",
    "\n",
    "viewer.add_image(mask, name='painted segments', channel_axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a8f7a-f903-49f4-857e-04775a29c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATASET_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
